{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataPositif.iloc[:,0]\n",
    "# dataPositif = pd.read_csv(\"dataset/sentimentIndonesia.csv\", sep=\"[\\t]\")\n",
    "# nonDep = dataPositif[(dataPositif.sentimen == 1)]\n",
    "# pd.DataFrame(nonDep.iloc[0:1000,:]).to_csv(\"dataset/sentimenIndonesia_Filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # pd.DataFrame(data[:row_dp2,:]).to_csv(\"dataset/akuDepresi_Filtered.csv\", index=False)\n",
    "# dep  = pd.read_csv(\"dataset/akuDepresi.csv\", usecols=['tweet'])\n",
    "# pd.DataFrame(dep.iloc[:1000,:]).to_csv(\"dataset/akuDepresi_Filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dep = dep.iloc[0:1000,:]\n",
    "# nonDep = pd.read_csv(\"dataset/sentimenIndonesia_Filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep  = pd.read_csv(\"dataset/akuDepresi_Filtered_Labeled.csv\")\n",
    "nonDep  = pd.read_csv(\"dataset/sentimenIndonesia_Filtered_Labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Username function\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove twitter handles (@user)\n",
    "dep['tidy_tweet'] = np.vectorize(remove_pattern)(dep['tweet'], \"@[\\w]*\")\n",
    "nonDep['tidy_tweet'] = np.vectorize(remove_pattern)(nonDep['Tweet'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters, numbers, punctuations\n",
    "dep['tidy_tweet'] = dep['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "nonDep['tidy_tweet'] = nonDep['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove shortwords (word length <=3)\n",
    "dep['tidy_tweet'] = dep['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "nonDep['tidy_tweet'] = nonDep['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove hashtag in front of words \n",
    "dep['tidy_tweet'] = dep['tidy_tweet'].str.replace(\"#([^\\s]+)\", \" \")\n",
    "nonDep['tidy_tweet'] = nonDep['tidy_tweet'].str.replace(\"#([^\\s]+)\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [lagunya, billie, marten, sangat, nostalgic, k...\n",
       "1    [Anjing, push, rank, kalah, teros, nilai, elek...\n",
       "2                         [kalo, kasus, depresi, bang]\n",
       "3    [Update, refer, hospital, Unit, psikatri, teta...\n",
       "4    [kenapa, banyak, orang, depresi, bundir, yang,...\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization depressive tweet\n",
    "tokenized_dep = dep['tidy_tweet'].apply(lambda x: x.split())\n",
    "tokenized_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rezeki, putus, inna, larizquna, lahu, fadesun...\n",
       "1    [makasih, ntar, kita, bagi, hasil, sisanya, bu...\n",
       "2    [akan, menjadi, satu, satunya, bukan, nomor, s...\n",
       "3    [dont, know, these, zikir, sangat, membantu, d...\n",
       "4                         [kamu, lebih, suka, diayomi]\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization non-depressive tweet\n",
    "tokenized_nonDep = nonDep['tidy_tweet'].apply(lambda x: x.split())\n",
    "tokenized_nonDep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "# import Sastrawi package\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [lagu, billie, marten, sangat, nostalgic, kaya...\n",
       "1    [anjing, push, rank, kalah, ros, nilai, elek, ...\n",
       "2                         [kalo, kasus, depresi, bang]\n",
       "3    [update, refer, hospital, unit, psikatri, teta...\n",
       "4    [kenapa, banyak, orang, depresi, bundir, yang,...\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dep = tokenized_dep.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "tokenized_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rezeki, putus, inna, larizquna, lahu, fadesun...\n",
       "1    [makasih, ntar, kita, bagi, hasil, sisa, buat,...\n",
       "2    [akan, jadi, satu, satu, bukan, nomor, satu, t...\n",
       "3    [dont, know, these, zikir, sangat, bantu, dapa...\n",
       "4                            [kamu, lebih, suka, ayom]\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_nonDep = tokenized_nonDep.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "tokenized_nonDep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lama', 'yang', 'jadi', 'favorit', 'laskar', 'pelangi']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_words = ' '.join([text for text in tokenized_dep['tidy_tweet']])\n",
    "# from wordcloud import WordCloud\n",
    "# wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "tokenized_nonDep[974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceURL(text):\n",
    "    \"\"\" Replaces url address with \"url\" \"\"\"\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URL\n",
    "nonDep['tidy_tweet'] = nonDep['tidy_tweet'].str.replace(\"((www\\.[^\\s]+)|(https?://[^\\s]+))\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doa rezeki tak putus inna haa zaa larizquna ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>rezeki putus inna larizquna lahu fadesungguhny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>makasih loh ntar kita bagi hasil aku 99 9 sisa...</td>\n",
       "      <td>0</td>\n",
       "      <td>makasih ntar kita bagi hasil sisanya buat kamu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ya aku akan menjadi satu satunya bukan nomor s...</td>\n",
       "      <td>0</td>\n",
       "      <td>akan menjadi satu satunya bukan nomor satu tet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know why but these zikir sangat membant...</td>\n",
       "      <td>0</td>\n",
       "      <td>dont know these zikir sangat membantu dapat ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aah kamu aja mas aku lebih suka diayomi</td>\n",
       "      <td>0</td>\n",
       "      <td>kamu lebih suka diayomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mau bantu aku nabung</td>\n",
       "      <td>0</td>\n",
       "      <td>bantu nabung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tak peduli seperti apa hidupmu kamu selalu pun...</td>\n",
       "      <td>0</td>\n",
       "      <td>peduli seperti hidupmu kamu selalu punya pilih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aku dah tahu macam mana nak bagi pengantin gel...</td>\n",
       "      <td>0</td>\n",
       "      <td>tahu macam mana bagi pengantin gelak natural h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cara nak mintak maaf ada 3 1 aku minta maaf 2 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>cara mintak maaf minta maaf mengaku salah yang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yuk netweetjen dibantu</td>\n",
       "      <td>0</td>\n",
       "      <td>netweetjen dibantu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ya allah ya tuhanku kau lindungilah kedua ibu ...</td>\n",
       "      <td>0</td>\n",
       "      <td>allah tuhanku lindungilah kedua bapaku disaat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>giveaway karena hari ini umur aku bertambah ja...</td>\n",
       "      <td>0</td>\n",
       "      <td>giveaway karena hari umur bertambah jadi ingin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ya allah ya tuhanku kau lindungilah kedua ibu ...</td>\n",
       "      <td>0</td>\n",
       "      <td>allah tuhanku lindungilah kedua bapaku disaat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>selamat hari jumat buat kamu yg selalu bikin r...</td>\n",
       "      <td>0</td>\n",
       "      <td>selamat hari jumat buat kamu selalu bikin rind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diremes di enyot ngedusel dusel di nenen kamu ...</td>\n",
       "      <td>0</td>\n",
       "      <td>diremes enyot ngedusel dusel nenen kamu mantap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hi rakyat2 ku karena akhirnyauga postelca aku ...</td>\n",
       "      <td>0</td>\n",
       "      <td>rakyat karena akhirnyauga postelca give away a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pilih salah satu yang paling kamu nyaman</td>\n",
       "      <td>0</td>\n",
       "      <td>pilih salah satu yang paling kamu nyaman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aku sendiri jugaaa yuk barengan</td>\n",
       "      <td>0</td>\n",
       "      <td>sendiri jugaaa barengan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mini giveaway berhubung aku ultah aku mau bagi...</td>\n",
       "      <td>0</td>\n",
       "      <td>mini giveaway berhubung ultah bagi rezeki puls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mantan kamu yang brengsek itu jangan dilupain ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mantan kamu yang brengsek jangan dilupain just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aryana tolong bukak mata besar besar pilihlah ...</td>\n",
       "      <td>0</td>\n",
       "      <td>aryana tolong bukak mata besar besar pilihlah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>buatlah cita cita kamu setinggi bintang di lan...</td>\n",
       "      <td>0</td>\n",
       "      <td>buatlah cita cita kamu setinggi bintang langit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cantik boleh la confess kat crush peluang kena...</td>\n",
       "      <td>0</td>\n",
       "      <td>cantik boleh confess crush peluang kena reject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cnta kmu ke aku tuh kyk fto albm tau g dbalk2 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>cnta albm dbalk brbh prnh brbh untk mnjdi trba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ini yang buat aku semakin yakin indonesia akan...</td>\n",
       "      <td>0</td>\n",
       "      <td>yang buat semakin yakin indonesia akan damai j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aku nk walk in ajelah senang</td>\n",
       "      <td>0</td>\n",
       "      <td>walk ajelah senang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jadilah seperti aku</td>\n",
       "      <td>0</td>\n",
       "      <td>jadilah seperti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sentiasa ingatkan diri jangan selalu tunjukkan...</td>\n",
       "      <td>0</td>\n",
       "      <td>sentiasa ingatkan diri jangan selalu tunjukkan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>temen temen yg ada di jatinangor dan sekitarny...</td>\n",
       "      <td>0</td>\n",
       "      <td>temen temen jatinangor sekitarnya bisa tolong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hahaa aku juga ga ngerti tadi tp asal jwb aja</td>\n",
       "      <td>0</td>\n",
       "      <td>hahaa juga ngerti tadi asal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>kamu baca aja disini ya 1 akun dari sekian rat...</td>\n",
       "      <td>0</td>\n",
       "      <td>kamu baca disini akun dari sekian ratus yang d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>ternyata masih belum saatnya aku tatap tatapan...</td>\n",
       "      <td>0</td>\n",
       "      <td>ternyata masih belum saatnya tatap tatapan sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>aku dilahirkan di bumi ni memang untuk jaga ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>dilahirkan bumi memang untuk jaga hati semua p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>dan jadikanlah aku termasuk orang orang yang m...</td>\n",
       "      <td>0</td>\n",
       "      <td>jadikanlah termasuk orang orang yang medapatka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>selama ini yang msh jadi favorit msh laskar pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>selama yang jadi favorit laskar pelangi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>kalau simpan duit asyik terguna jadi aku beli ...</td>\n",
       "      <td>0</td>\n",
       "      <td>kalau simpan duit asyik terguna jadi beli emas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>terima kasih ginting caramu bangkit dari kekal...</td>\n",
       "      <td>0</td>\n",
       "      <td>terima kasih ginting caramu bangkit dari kekal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>aku juga dong</td>\n",
       "      <td>0</td>\n",
       "      <td>juga dong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>crush kalau nak tegur ye tegur kalau suka caka...</td>\n",
       "      <td>0</td>\n",
       "      <td>crush kalau tegur tegur kalau suka cakap suka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>ya ya ya dan aku tahu sekarang</td>\n",
       "      <td>0</td>\n",
       "      <td>tahu sekarang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>itu aku jg mau</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>teruntuk kak rehan kamu yg sabar ya</td>\n",
       "      <td>0</td>\n",
       "      <td>teruntuk rehan kamu sabar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>aku legaaaaa hampir nggakbisa menikmati makan ...</td>\n",
       "      <td>0</td>\n",
       "      <td>legaaaaa hampir nggakbisa menikmati makan siang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>semoga apa yang kamu berikan padaku saat ini b...</td>\n",
       "      <td>0</td>\n",
       "      <td>semoga yang kamu berikan padaku saat bukanlah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>t kasih semua kalau nak bantu aku kumpul duit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>kasih semua kalau bantu kumpul duit lagi banya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>kalau takut dilambung ombak jangan menonton om...</td>\n",
       "      <td>0</td>\n",
       "      <td>kalau takut dilambung ombak jangan menonton om...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>soal jodoh ni aku tenang je tapi aku harap bil...</td>\n",
       "      <td>0</td>\n",
       "      <td>soal jodoh tenang tapi harap bila jodoh sampai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>mau nya kamu itu sih hahaha</td>\n",
       "      <td>0</td>\n",
       "      <td>kamu hahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>aku setia kok sama kakak</td>\n",
       "      <td>0</td>\n",
       "      <td>setia sama kakak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>hahahahahahahaha aku pun ada sejarah dgn wani ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hahahahahahahaha sejarah wani nasib kaklong id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>hahahahaha anggap jelah dia respect orang lain...</td>\n",
       "      <td>0</td>\n",
       "      <td>hahahahaha anggap jelah respect orang lain yan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>mamat ni cool cinta dlm hati dia tu seputih ka...</td>\n",
       "      <td>0</td>\n",
       "      <td>mamat cool cinta hati seputih kain belom dicem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>ga ada masalah kok yg masalah itu kalo kamu sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>masalah masalah kalo kamu sama sekali nggak mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>untuk merayakan kemenangan straykids hari ini ...</td>\n",
       "      <td>0</td>\n",
       "      <td>untuk merayakan kemenangan straykids hari zona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>aku cinta reveluv</td>\n",
       "      <td>0</td>\n",
       "      <td>cinta reveluv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>setau aku di koriyah emg gitu hehe</td>\n",
       "      <td>0</td>\n",
       "      <td>setau koriyah gitu hehe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>gak apa apa deh aku gak punya pacar asal bisa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>punya pacar asal bisa diginiin terus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>manusia bro ex aku banyak kali juga cakap camn...</td>\n",
       "      <td>0</td>\n",
       "      <td>manusia banyak kali juga cakap camni tahun kek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>tapi aku bersyukur sbb allah pinjamkan kau wla...</td>\n",
       "      <td>0</td>\n",
       "      <td>tapi bersyukur allah pinjamkan wlaupun kejap t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>orang lain kemain minat dia aku lek je orang a...</td>\n",
       "      <td>0</td>\n",
       "      <td>orang lain kemain minat orang amik gambar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet  label  \\\n",
       "0    doa rezeki tak putus inna haa zaa larizquna ma...      0   \n",
       "1    makasih loh ntar kita bagi hasil aku 99 9 sisa...      0   \n",
       "2    ya aku akan menjadi satu satunya bukan nomor s...      0   \n",
       "3    i dont know why but these zikir sangat membant...      0   \n",
       "4              aah kamu aja mas aku lebih suka diayomi      0   \n",
       "5                                 mau bantu aku nabung      0   \n",
       "6    tak peduli seperti apa hidupmu kamu selalu pun...      0   \n",
       "7    aku dah tahu macam mana nak bagi pengantin gel...      0   \n",
       "8    cara nak mintak maaf ada 3 1 aku minta maaf 2 ...      0   \n",
       "9                               yuk netweetjen dibantu      0   \n",
       "10   ya allah ya tuhanku kau lindungilah kedua ibu ...      0   \n",
       "11   giveaway karena hari ini umur aku bertambah ja...      0   \n",
       "12   ya allah ya tuhanku kau lindungilah kedua ibu ...      0   \n",
       "13   selamat hari jumat buat kamu yg selalu bikin r...      0   \n",
       "14   diremes di enyot ngedusel dusel di nenen kamu ...      0   \n",
       "15   hi rakyat2 ku karena akhirnyauga postelca aku ...      0   \n",
       "16            pilih salah satu yang paling kamu nyaman      0   \n",
       "17                     aku sendiri jugaaa yuk barengan      0   \n",
       "18   mini giveaway berhubung aku ultah aku mau bagi...      0   \n",
       "19   mantan kamu yang brengsek itu jangan dilupain ...      0   \n",
       "20   aryana tolong bukak mata besar besar pilihlah ...      0   \n",
       "21   buatlah cita cita kamu setinggi bintang di lan...      0   \n",
       "22   cantik boleh la confess kat crush peluang kena...      0   \n",
       "23   cnta kmu ke aku tuh kyk fto albm tau g dbalk2 ...      0   \n",
       "24   ini yang buat aku semakin yakin indonesia akan...      0   \n",
       "25                        aku nk walk in ajelah senang      0   \n",
       "26                                 jadilah seperti aku      0   \n",
       "27   sentiasa ingatkan diri jangan selalu tunjukkan...      0   \n",
       "28   temen temen yg ada di jatinangor dan sekitarny...      0   \n",
       "29       hahaa aku juga ga ngerti tadi tp asal jwb aja      0   \n",
       "..                                                 ...    ...   \n",
       "970  kamu baca aja disini ya 1 akun dari sekian rat...      0   \n",
       "971  ternyata masih belum saatnya aku tatap tatapan...      0   \n",
       "972  aku dilahirkan di bumi ni memang untuk jaga ha...      0   \n",
       "973  dan jadikanlah aku termasuk orang orang yang m...      0   \n",
       "974  selama ini yang msh jadi favorit msh laskar pe...      0   \n",
       "975  kalau simpan duit asyik terguna jadi aku beli ...      0   \n",
       "976  terima kasih ginting caramu bangkit dari kekal...      0   \n",
       "977                                      aku juga dong      0   \n",
       "978  crush kalau nak tegur ye tegur kalau suka caka...      0   \n",
       "979                     ya ya ya dan aku tahu sekarang      0   \n",
       "980                                     itu aku jg mau      0   \n",
       "981                teruntuk kak rehan kamu yg sabar ya      0   \n",
       "982  aku legaaaaa hampir nggakbisa menikmati makan ...      0   \n",
       "983  semoga apa yang kamu berikan padaku saat ini b...      0   \n",
       "984  t kasih semua kalau nak bantu aku kumpul duit ...      0   \n",
       "985  kalau takut dilambung ombak jangan menonton om...      0   \n",
       "986  soal jodoh ni aku tenang je tapi aku harap bil...      0   \n",
       "987                        mau nya kamu itu sih hahaha      0   \n",
       "988                           aku setia kok sama kakak      0   \n",
       "989  hahahahahahahaha aku pun ada sejarah dgn wani ...      0   \n",
       "990  hahahahaha anggap jelah dia respect orang lain...      0   \n",
       "991  mamat ni cool cinta dlm hati dia tu seputih ka...      0   \n",
       "992  ga ada masalah kok yg masalah itu kalo kamu sa...      0   \n",
       "993  untuk merayakan kemenangan straykids hari ini ...      0   \n",
       "994                                  aku cinta reveluv      0   \n",
       "995                 setau aku di koriyah emg gitu hehe      0   \n",
       "996  gak apa apa deh aku gak punya pacar asal bisa ...      0   \n",
       "997  manusia bro ex aku banyak kali juga cakap camn...      0   \n",
       "998  tapi aku bersyukur sbb allah pinjamkan kau wla...      0   \n",
       "999  orang lain kemain minat dia aku lek je orang a...      0   \n",
       "\n",
       "                                            tidy_tweet  \n",
       "0    rezeki putus inna larizquna lahu fadesungguhny...  \n",
       "1       makasih ntar kita bagi hasil sisanya buat kamu  \n",
       "2    akan menjadi satu satunya bukan nomor satu tet...  \n",
       "3    dont know these zikir sangat membantu dapat ha...  \n",
       "4                              kamu lebih suka diayomi  \n",
       "5                                         bantu nabung  \n",
       "6    peduli seperti hidupmu kamu selalu punya pilih...  \n",
       "7    tahu macam mana bagi pengantin gelak natural h...  \n",
       "8    cara mintak maaf minta maaf mengaku salah yang...  \n",
       "9                                   netweetjen dibantu  \n",
       "10   allah tuhanku lindungilah kedua bapaku disaat ...  \n",
       "11   giveaway karena hari umur bertambah jadi ingin...  \n",
       "12   allah tuhanku lindungilah kedua bapaku disaat ...  \n",
       "13   selamat hari jumat buat kamu selalu bikin rind...  \n",
       "14      diremes enyot ngedusel dusel nenen kamu mantap  \n",
       "15   rakyat karena akhirnyauga postelca give away a...  \n",
       "16            pilih salah satu yang paling kamu nyaman  \n",
       "17                             sendiri jugaaa barengan  \n",
       "18   mini giveaway berhubung ultah bagi rezeki puls...  \n",
       "19   mantan kamu yang brengsek jangan dilupain just...  \n",
       "20   aryana tolong bukak mata besar besar pilihlah ...  \n",
       "21   buatlah cita cita kamu setinggi bintang langit...  \n",
       "22   cantik boleh confess crush peluang kena reject...  \n",
       "23   cnta albm dbalk brbh prnh brbh untk mnjdi trba...  \n",
       "24   yang buat semakin yakin indonesia akan damai j...  \n",
       "25                                  walk ajelah senang  \n",
       "26                                     jadilah seperti  \n",
       "27   sentiasa ingatkan diri jangan selalu tunjukkan...  \n",
       "28   temen temen jatinangor sekitarnya bisa tolong ...  \n",
       "29                         hahaa juga ngerti tadi asal  \n",
       "..                                                 ...  \n",
       "970  kamu baca disini akun dari sekian ratus yang d...  \n",
       "971  ternyata masih belum saatnya tatap tatapan sam...  \n",
       "972  dilahirkan bumi memang untuk jaga hati semua p...  \n",
       "973  jadikanlah termasuk orang orang yang medapatka...  \n",
       "974            selama yang jadi favorit laskar pelangi  \n",
       "975  kalau simpan duit asyik terguna jadi beli emas...  \n",
       "976  terima kasih ginting caramu bangkit dari kekal...  \n",
       "977                                          juga dong  \n",
       "978  crush kalau tegur tegur kalau suka cakap suka ...  \n",
       "979                                      tahu sekarang  \n",
       "980                                                     \n",
       "981                          teruntuk rehan kamu sabar  \n",
       "982    legaaaaa hampir nggakbisa menikmati makan siang  \n",
       "983  semoga yang kamu berikan padaku saat bukanlah ...  \n",
       "984  kasih semua kalau bantu kumpul duit lagi banya...  \n",
       "985  kalau takut dilambung ombak jangan menonton om...  \n",
       "986  soal jodoh tenang tapi harap bila jodoh sampai...  \n",
       "987                                        kamu hahaha  \n",
       "988                                   setia sama kakak  \n",
       "989  hahahahahahahaha sejarah wani nasib kaklong id...  \n",
       "990  hahahahaha anggap jelah respect orang lain yan...  \n",
       "991  mamat cool cinta hati seputih kain belom dicem...  \n",
       "992  masalah masalah kalo kamu sama sekali nggak mu...  \n",
       "993  untuk merayakan kemenangan straykids hari zona...  \n",
       "994                                      cinta reveluv  \n",
       "995                            setau koriyah gitu hehe  \n",
       "996               punya pacar asal bisa diginiin terus  \n",
       "997  manusia banyak kali juga cakap camni tahun kek...  \n",
       "998  tapi bersyukur allah pinjamkan wlaupun kejap t...  \n",
       "999          orang lain kemain minat orang amik gambar  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonDep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Depressive + Positive Tweets and Split Data into Training&Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Positive and Depressive Tweets\n",
    "comb = nonDep.iloc[:,1:3].append(dep.iloc[:,1:3], ignore_index=True)\n",
    "\n",
    "total_tweets = 1000 + 1000\n",
    "\n",
    "trainIndex, testIndex = list(), list()\n",
    "for i in range(comb.shape[0]):\n",
    "    if np.random.uniform(0, 1) < 0.95:\n",
    "        trainIndex += [i]\n",
    "    else:\n",
    "        testIndex += [i]\n",
    "trainData = comb.iloc[trainIndex]\n",
    "testData = comb.iloc[testIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_bow = bow[:31962,:]\n",
    "# test_bow = bow[31962:,:]\n",
    "trainData.to_csv('trainData_randomize.csv', index=False)\n",
    "trainDataCSV = pd.read_csv('trainData_randomize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-69ebbeb5887b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# bag-of-words feature matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbowF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbow_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainDataCSV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tidy_tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 266\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[0;32m    120\u001b[0m                              \"unicode string.\")\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000)\n",
    "\n",
    "# bag-of-words feature matrix\n",
    "bowF = bow_vectorizer.fit_transform(trainDataCSV['tidy_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction import text\n",
    "\n",
    "# tambahan = open('stopword.txt', 'r')\n",
    "# lines = tambahan.readlines()\n",
    "# lines.str.replace(\"[\\n]\", \"\")\n",
    "# print(lines)\n",
    "# my_stop_words = text.ENGLISH_STOP_WORDS.union('stopword.txt')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000)\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(trainDataCSV['tidy_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model using Bag-of-Words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
